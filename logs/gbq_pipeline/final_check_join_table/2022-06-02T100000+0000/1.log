[2022-06-06 14:22:07,169] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.final_check_join_table 2022-06-02T10:00:00+00:00 [queued]>
[2022-06-06 14:22:07,184] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.final_check_join_table 2022-06-02T10:00:00+00:00 [queued]>
[2022-06-06 14:22:07,184] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 14:22:07,185] {taskinstance.py:1043} INFO - Starting attempt 1 of 3
[2022-06-06 14:22:07,185] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 14:22:07,195] {taskinstance.py:1063} INFO - Executing <Task(BigQueryCheckOperator): final_check_join_table> on 2022-06-02T10:00:00+00:00
[2022-06-06 14:22:07,200] {standard_task_runner.py:52} INFO - Started process 122 to run task
[2022-06-06 14:22:07,203] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'gbq_pipeline', 'final_check_join_table', '2022-06-02T10:00:00+00:00', '--job-id', '307', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/gbq_pipeline.py', '--cfg-path', '/tmp/tmp2na80pih', '--error-file', '/tmp/tmp25ubcncw']
[2022-06-06 14:22:07,205] {standard_task_runner.py:77} INFO - Job 307: Subtask final_check_join_table
[2022-06-06 14:22:07,238] {logging_mixin.py:104} INFO - Running <TaskInstance: gbq_pipeline.final_check_join_table 2022-06-02T10:00:00+00:00 [running]> on host 92fcc90275da
[2022-06-06 14:22:07,268] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=airflow@airflow.com
AIRFLOW_CTX_DAG_OWNER=vanmai-airflow
AIRFLOW_CTX_DAG_ID=gbq_pipeline
AIRFLOW_CTX_TASK_ID=final_check_join_table
AIRFLOW_CTX_EXECUTION_DATE=2022-06-02T10:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-02T10:00:00+00:00
[2022-06-06 14:22:07,269] {sql.py:87} INFO - Executing SQL check: 
    SELECT "20220602" =
        (
        SELECT max(date)
        FROM `airflow-project-352316.github_curated.github_hackernews_join`
        )
    
[2022-06-06 14:22:07,277] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:120 DeprecationWarning: This method will be deprecated. Please use `BigQueryHook.get_client` method
[2022-06-06 14:22:07,542] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:2052 DeprecationWarning: This method is deprecated. Please use `BigQueryHook.insert_job` method.
[2022-06-06 14:22:07,543] {bigquery.py:1510} INFO - Inserting job airflow_1654525327543147_3d9dd53d620bcdcd2286739eb79e3561
[2022-06-06 14:22:09,169] {sql.py:90} INFO - Record: [True]
[2022-06-06 14:22:09,169] {sql.py:96} INFO - Success.
[2022-06-06 14:22:09,177] {taskinstance.py:1166} INFO - Marking task as SUCCESS. dag_id=gbq_pipeline, task_id=final_check_join_table, execution_date=20220602T100000, start_date=20220606T142207, end_date=20220606T142209
[2022-06-06 14:22:09,196] {taskinstance.py:1220} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-06 14:22:09,223] {local_task_job.py:146} INFO - Task exited with return code 0
[2022-06-06 17:01:55,547] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.final_check_join_table 2022-06-02T10:00:00+00:00 [queued]>
[2022-06-06 17:01:55,565] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.final_check_join_table 2022-06-02T10:00:00+00:00 [queued]>
[2022-06-06 17:01:55,565] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 17:01:55,566] {taskinstance.py:1043} INFO - Starting attempt 1 of 3
[2022-06-06 17:01:55,566] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 17:01:55,572] {taskinstance.py:1063} INFO - Executing <Task(BigQueryCheckOperator): final_check_join_table> on 2022-06-02T10:00:00+00:00
[2022-06-06 17:01:55,576] {standard_task_runner.py:52} INFO - Started process 876 to run task
[2022-06-06 17:01:55,579] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'gbq_pipeline', 'final_check_join_table', '2022-06-02T10:00:00+00:00', '--job-id', '591', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/gbq_pipeline.py', '--cfg-path', '/tmp/tmpyj45win5', '--error-file', '/tmp/tmpt05yy36o']
[2022-06-06 17:01:55,580] {standard_task_runner.py:77} INFO - Job 591: Subtask final_check_join_table
[2022-06-06 17:01:55,611] {logging_mixin.py:104} INFO - Running <TaskInstance: gbq_pipeline.final_check_join_table 2022-06-02T10:00:00+00:00 [running]> on host c40819a450e3
[2022-06-06 17:01:55,639] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=airflow@airflow.com
AIRFLOW_CTX_DAG_OWNER=vanmai-airflow
AIRFLOW_CTX_DAG_ID=gbq_pipeline
AIRFLOW_CTX_TASK_ID=final_check_join_table
AIRFLOW_CTX_EXECUTION_DATE=2022-06-02T10:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-02T10:00:00+00:00
[2022-06-06 17:01:55,641] {sql.py:87} INFO - Executing SQL check: 
    SELECT "20220602" =
        (
        SELECT max(date)
        FROM `airflow-project-352316.github_curated.github_hackernews_join`
        )
    
[2022-06-06 17:01:55,648] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:120 DeprecationWarning: This method will be deprecated. Please use `BigQueryHook.get_client` method
[2022-06-06 17:01:56,105] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:2052 DeprecationWarning: This method is deprecated. Please use `BigQueryHook.insert_job` method.
[2022-06-06 17:01:56,106] {bigquery.py:1510} INFO - Inserting job airflow_1654534916105787_3d9dd53d620bcdcd2286739eb79e3561
[2022-06-06 17:01:57,563] {sql.py:90} INFO - Record: [False]
[2022-06-06 17:01:57,569] {taskinstance.py:1455} ERROR - Test failed.
Query:

    SELECT "20220602" =
        (
        SELECT max(date)
        FROM `airflow-project-352316.github_curated.github_hackernews_join`
        )
    
Results:
[False]
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1112, in _run_raw_task
    self._prepare_and_execute_task_with_callbacks(context, task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1285, in _prepare_and_execute_task_with_callbacks
    result = self._execute_task(context, task_copy)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1315, in _execute_task
    result = task_copy.execute(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/sql.py", line 94, in execute
    raise AirflowException(f"Test failed.\nQuery:\n{self.sql}\nResults:\n{records!s}")
airflow.exceptions.AirflowException: Test failed.
Query:

    SELECT "20220602" =
        (
        SELECT max(date)
        FROM `airflow-project-352316.github_curated.github_hackernews_join`
        )
    
Results:
[False]
[2022-06-06 17:01:57,571] {taskinstance.py:1503} INFO - Marking task as UP_FOR_RETRY. dag_id=gbq_pipeline, task_id=final_check_join_table, execution_date=20220602T100000, start_date=20220606T170155, end_date=20220606T170157
[2022-06-06 17:01:57,600] {local_task_job.py:146} INFO - Task exited with return code 1
[2022-06-06 17:10:49,598] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.final_check_join_table 2022-06-02T10:00:00+00:00 [queued]>
[2022-06-06 17:10:49,618] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.final_check_join_table 2022-06-02T10:00:00+00:00 [queued]>
[2022-06-06 17:10:49,618] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 17:10:49,619] {taskinstance.py:1043} INFO - Starting attempt 1 of 3
[2022-06-06 17:10:49,619] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 17:10:49,627] {taskinstance.py:1063} INFO - Executing <Task(BigQueryCheckOperator): final_check_join_table> on 2022-06-02T10:00:00+00:00
[2022-06-06 17:10:49,632] {standard_task_runner.py:52} INFO - Started process 989 to run task
[2022-06-06 17:10:49,635] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'gbq_pipeline', 'final_check_join_table', '2022-06-02T10:00:00+00:00', '--job-id', '629', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/gbq_pipeline.py', '--cfg-path', '/tmp/tmp201c76tw', '--error-file', '/tmp/tmpbvtyi41m']
[2022-06-06 17:10:49,636] {standard_task_runner.py:77} INFO - Job 629: Subtask final_check_join_table
[2022-06-06 17:10:49,672] {logging_mixin.py:104} INFO - Running <TaskInstance: gbq_pipeline.final_check_join_table 2022-06-02T10:00:00+00:00 [running]> on host c40819a450e3
[2022-06-06 17:10:49,706] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=airflow@airflow.com
AIRFLOW_CTX_DAG_OWNER=vanmai-airflow
AIRFLOW_CTX_DAG_ID=gbq_pipeline
AIRFLOW_CTX_TASK_ID=final_check_join_table
AIRFLOW_CTX_EXECUTION_DATE=2022-06-02T10:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-02T10:00:00+00:00
[2022-06-06 17:10:49,708] {sql.py:87} INFO - Executing SQL check: 
    SELECT "20220602" =
        (
        SELECT max(date)
        FROM `airflow-project-352316.github_curated.github_hackernews_join`
        )
    
[2022-06-06 17:10:49,716] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:120 DeprecationWarning: This method will be deprecated. Please use `BigQueryHook.get_client` method
[2022-06-06 17:10:50,122] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:2052 DeprecationWarning: This method is deprecated. Please use `BigQueryHook.insert_job` method.
[2022-06-06 17:10:50,124] {bigquery.py:1510} INFO - Inserting job airflow_1654535450123332_3d9dd53d620bcdcd2286739eb79e3561
[2022-06-06 17:10:51,563] {sql.py:90} INFO - Record: [True]
[2022-06-06 17:10:51,564] {sql.py:96} INFO - Success.
[2022-06-06 17:10:51,574] {taskinstance.py:1166} INFO - Marking task as SUCCESS. dag_id=gbq_pipeline, task_id=final_check_join_table, execution_date=20220602T100000, start_date=20220606T171049, end_date=20220606T171051
[2022-06-06 17:10:51,593] {taskinstance.py:1220} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-06 17:10:51,617] {local_task_job.py:146} INFO - Task exited with return code 0
[2022-06-06 19:50:33,377] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.final_check_join_table 2022-06-02T10:00:00+00:00 [queued]>
[2022-06-06 19:50:33,389] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.final_check_join_table 2022-06-02T10:00:00+00:00 [queued]>
[2022-06-06 19:50:33,390] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 19:50:33,390] {taskinstance.py:1043} INFO - Starting attempt 1 of 3
[2022-06-06 19:50:33,391] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 19:50:33,400] {taskinstance.py:1063} INFO - Executing <Task(BigQueryCheckOperator): final_check_join_table> on 2022-06-02T10:00:00+00:00
[2022-06-06 19:50:33,404] {standard_task_runner.py:52} INFO - Started process 100 to run task
[2022-06-06 19:50:33,406] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'gbq_pipeline', 'final_check_join_table', '2022-06-02T10:00:00+00:00', '--job-id', '787', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/gbq_pipeline.py', '--cfg-path', '/tmp/tmpt39dv0h1', '--error-file', '/tmp/tmpu2650x1z']
[2022-06-06 19:50:33,408] {standard_task_runner.py:77} INFO - Job 787: Subtask final_check_join_table
[2022-06-06 19:50:33,437] {logging_mixin.py:104} INFO - Running <TaskInstance: gbq_pipeline.final_check_join_table 2022-06-02T10:00:00+00:00 [running]> on host e8b9b26156db
[2022-06-06 19:50:33,464] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=airflow@airflow.com
AIRFLOW_CTX_DAG_OWNER=vanmai-airflow
AIRFLOW_CTX_DAG_ID=gbq_pipeline
AIRFLOW_CTX_TASK_ID=final_check_join_table
AIRFLOW_CTX_EXECUTION_DATE=2022-06-02T10:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-02T10:00:00+00:00
[2022-06-06 19:50:33,465] {sql.py:87} INFO - Executing SQL check: 
    SELECT "20220602" =
        (
        SELECT max(date)
        FROM `airflow-docker-352518.us_curated_data.github_hackernews_join`
        )
    
[2022-06-06 19:50:33,472] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:120 DeprecationWarning: This method will be deprecated. Please use `BigQueryHook.get_client` method
[2022-06-06 19:50:33,914] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:2052 DeprecationWarning: This method is deprecated. Please use `BigQueryHook.insert_job` method.
[2022-06-06 19:50:33,915] {bigquery.py:1510} INFO - Inserting job airflow_1654545033914671_124a9c782e3fe409cbf115734baafb4e
[2022-06-06 19:50:35,547] {sql.py:90} INFO - Record: [False]
[2022-06-06 19:50:35,554] {taskinstance.py:1455} ERROR - Test failed.
Query:

    SELECT "20220602" =
        (
        SELECT max(date)
        FROM `airflow-docker-352518.us_curated_data.github_hackernews_join`
        )
    
Results:
[False]
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1112, in _run_raw_task
    self._prepare_and_execute_task_with_callbacks(context, task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1285, in _prepare_and_execute_task_with_callbacks
    result = self._execute_task(context, task_copy)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1315, in _execute_task
    result = task_copy.execute(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/sql.py", line 94, in execute
    raise AirflowException(f"Test failed.\nQuery:\n{self.sql}\nResults:\n{records!s}")
airflow.exceptions.AirflowException: Test failed.
Query:

    SELECT "20220602" =
        (
        SELECT max(date)
        FROM `airflow-docker-352518.us_curated_data.github_hackernews_join`
        )
    
Results:
[False]
[2022-06-06 19:50:35,556] {taskinstance.py:1503} INFO - Marking task as UP_FOR_RETRY. dag_id=gbq_pipeline, task_id=final_check_join_table, execution_date=20220602T100000, start_date=20220606T195033, end_date=20220606T195035
[2022-06-06 19:50:35,589] {local_task_job.py:146} INFO - Task exited with return code 1
[2022-06-06 19:58:28,694] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.final_check_join_table 2022-06-02T10:00:00+00:00 [queued]>
[2022-06-06 19:58:28,711] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.final_check_join_table 2022-06-02T10:00:00+00:00 [queued]>
[2022-06-06 19:58:28,712] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 19:58:28,712] {taskinstance.py:1043} INFO - Starting attempt 1 of 3
[2022-06-06 19:58:28,712] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 19:58:28,722] {taskinstance.py:1063} INFO - Executing <Task(BigQueryCheckOperator): final_check_join_table> on 2022-06-02T10:00:00+00:00
[2022-06-06 19:58:28,726] {standard_task_runner.py:52} INFO - Started process 203 to run task
[2022-06-06 19:58:28,728] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'gbq_pipeline', 'final_check_join_table', '2022-06-02T10:00:00+00:00', '--job-id', '823', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/gbq_pipeline.py', '--cfg-path', '/tmp/tmp74rrnn5d', '--error-file', '/tmp/tmpiizbaggw']
[2022-06-06 19:58:28,730] {standard_task_runner.py:77} INFO - Job 823: Subtask final_check_join_table
[2022-06-06 19:58:28,760] {logging_mixin.py:104} INFO - Running <TaskInstance: gbq_pipeline.final_check_join_table 2022-06-02T10:00:00+00:00 [running]> on host e8b9b26156db
[2022-06-06 19:58:28,788] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=airflow@airflow.com
AIRFLOW_CTX_DAG_OWNER=vanmai-airflow
AIRFLOW_CTX_DAG_ID=gbq_pipeline
AIRFLOW_CTX_TASK_ID=final_check_join_table
AIRFLOW_CTX_EXECUTION_DATE=2022-06-02T10:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-02T10:00:00+00:00
[2022-06-06 19:58:28,789] {sql.py:87} INFO - Executing SQL check: 
    SELECT "20220602" =
        (
        SELECT max(date)
        FROM `airflow-docker-352518.us_curated_data.github_hackernews_join`
        )
    
[2022-06-06 19:58:28,796] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:120 DeprecationWarning: This method will be deprecated. Please use `BigQueryHook.get_client` method
[2022-06-06 19:58:29,176] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:2052 DeprecationWarning: This method is deprecated. Please use `BigQueryHook.insert_job` method.
[2022-06-06 19:58:29,177] {bigquery.py:1510} INFO - Inserting job airflow_1654545509176746_124a9c782e3fe409cbf115734baafb4e
[2022-06-06 19:58:30,680] {sql.py:90} INFO - Record: [True]
[2022-06-06 19:58:30,680] {sql.py:96} INFO - Success.
[2022-06-06 19:58:30,695] {taskinstance.py:1166} INFO - Marking task as SUCCESS. dag_id=gbq_pipeline, task_id=final_check_join_table, execution_date=20220602T100000, start_date=20220606T195828, end_date=20220606T195830
[2022-06-06 19:58:30,713] {taskinstance.py:1220} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-06 19:58:30,752] {local_task_job.py:146} INFO - Task exited with return code 0
[2022-06-06 20:01:46,859] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.final_check_join_table 2022-06-02T10:00:00+00:00 [queued]>
[2022-06-06 20:01:46,873] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.final_check_join_table 2022-06-02T10:00:00+00:00 [queued]>
[2022-06-06 20:01:46,874] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 20:01:46,874] {taskinstance.py:1043} INFO - Starting attempt 1 of 3
[2022-06-06 20:01:46,874] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 20:01:46,883] {taskinstance.py:1063} INFO - Executing <Task(BigQueryCheckOperator): final_check_join_table> on 2022-06-02T10:00:00+00:00
[2022-06-06 20:01:46,887] {standard_task_runner.py:52} INFO - Started process 261 to run task
[2022-06-06 20:01:46,890] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'gbq_pipeline', 'final_check_join_table', '2022-06-02T10:00:00+00:00', '--job-id', '844', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/gbq_pipeline.py', '--cfg-path', '/tmp/tmplp1lnang', '--error-file', '/tmp/tmps4frh6e3']
[2022-06-06 20:01:46,892] {standard_task_runner.py:77} INFO - Job 844: Subtask final_check_join_table
[2022-06-06 20:01:46,923] {logging_mixin.py:104} INFO - Running <TaskInstance: gbq_pipeline.final_check_join_table 2022-06-02T10:00:00+00:00 [running]> on host e8b9b26156db
[2022-06-06 20:01:46,951] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=airflow@airflow.com
AIRFLOW_CTX_DAG_OWNER=vanmai-airflow
AIRFLOW_CTX_DAG_ID=gbq_pipeline
AIRFLOW_CTX_TASK_ID=final_check_join_table
AIRFLOW_CTX_EXECUTION_DATE=2022-06-02T10:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-02T10:00:00+00:00
[2022-06-06 20:01:46,953] {sql.py:87} INFO - Executing SQL check: 
    SELECT "20220602" =
        (
        SELECT max(date)
        FROM `airflow-docker-352518.us_curated_data.github_hackernews_join`
        )
    
[2022-06-06 20:01:46,960] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:120 DeprecationWarning: This method will be deprecated. Please use `BigQueryHook.get_client` method
[2022-06-06 20:01:47,293] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:2052 DeprecationWarning: This method is deprecated. Please use `BigQueryHook.insert_job` method.
[2022-06-06 20:01:47,294] {bigquery.py:1510} INFO - Inserting job airflow_1654545707294146_124a9c782e3fe409cbf115734baafb4e
[2022-06-06 20:01:49,236] {sql.py:90} INFO - Record: [True]
[2022-06-06 20:01:49,237] {sql.py:96} INFO - Success.
[2022-06-06 20:01:49,246] {taskinstance.py:1166} INFO - Marking task as SUCCESS. dag_id=gbq_pipeline, task_id=final_check_join_table, execution_date=20220602T100000, start_date=20220606T200146, end_date=20220606T200149
[2022-06-06 20:01:49,262] {taskinstance.py:1220} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-06 20:01:49,274] {local_task_job.py:146} INFO - Task exited with return code 0
