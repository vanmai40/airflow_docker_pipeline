[2022-06-06 15:23:33,056] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.final_check_join_table 2022-03-01T10:00:00+00:00 [queued]>
[2022-06-06 15:23:33,065] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.final_check_join_table 2022-03-01T10:00:00+00:00 [queued]>
[2022-06-06 15:23:33,065] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 15:23:33,065] {taskinstance.py:1043} INFO - Starting attempt 1 of 3
[2022-06-06 15:23:33,066] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 15:23:33,075] {taskinstance.py:1063} INFO - Executing <Task(BigQueryCheckOperator): final_check_join_table> on 2022-03-01T10:00:00+00:00
[2022-06-06 15:23:33,078] {standard_task_runner.py:52} INFO - Started process 258 to run task
[2022-06-06 15:23:33,081] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'gbq_pipeline', 'final_check_join_table', '2022-03-01T10:00:00+00:00', '--job-id', '385', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/gbq_pipeline.py', '--cfg-path', '/tmp/tmp0dnko3c0', '--error-file', '/tmp/tmpx4wshro3']
[2022-06-06 15:23:33,082] {standard_task_runner.py:77} INFO - Job 385: Subtask final_check_join_table
[2022-06-06 15:23:33,113] {logging_mixin.py:104} INFO - Running <TaskInstance: gbq_pipeline.final_check_join_table 2022-03-01T10:00:00+00:00 [running]> on host c40819a450e3
[2022-06-06 15:23:33,142] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=airflow@airflow.com
AIRFLOW_CTX_DAG_OWNER=vanmai-airflow
AIRFLOW_CTX_DAG_ID=gbq_pipeline
AIRFLOW_CTX_TASK_ID=final_check_join_table
AIRFLOW_CTX_EXECUTION_DATE=2022-03-01T10:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-01T10:00:00+00:00
[2022-06-06 15:23:33,144] {sql.py:87} INFO - Executing SQL check: 
    SELECT "20220301" =
        (
        SELECT max(date)
        FROM `airflow-project-352316.github_curated.github_hackernews_join`
        )
    
[2022-06-06 15:23:33,151] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:120 DeprecationWarning: This method will be deprecated. Please use `BigQueryHook.get_client` method
[2022-06-06 15:23:33,566] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:2052 DeprecationWarning: This method is deprecated. Please use `BigQueryHook.insert_job` method.
[2022-06-06 15:23:33,567] {bigquery.py:1510} INFO - Inserting job airflow_1654529013566729_f01443e709b4b479ef0cdf08a32ea191
[2022-06-06 15:23:35,168] {sql.py:90} INFO - Record: [False]
[2022-06-06 15:23:35,174] {taskinstance.py:1455} ERROR - Test failed.
Query:

    SELECT "20220301" =
        (
        SELECT max(date)
        FROM `airflow-project-352316.github_curated.github_hackernews_join`
        )
    
Results:
[False]
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1112, in _run_raw_task
    self._prepare_and_execute_task_with_callbacks(context, task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1285, in _prepare_and_execute_task_with_callbacks
    result = self._execute_task(context, task_copy)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1315, in _execute_task
    result = task_copy.execute(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/sql.py", line 94, in execute
    raise AirflowException(f"Test failed.\nQuery:\n{self.sql}\nResults:\n{records!s}")
airflow.exceptions.AirflowException: Test failed.
Query:

    SELECT "20220301" =
        (
        SELECT max(date)
        FROM `airflow-project-352316.github_curated.github_hackernews_join`
        )
    
Results:
[False]
[2022-06-06 15:23:35,176] {taskinstance.py:1503} INFO - Marking task as UP_FOR_RETRY. dag_id=gbq_pipeline, task_id=final_check_join_table, execution_date=20220301T100000, start_date=20220606T152333, end_date=20220606T152335
[2022-06-06 15:23:35,222] {local_task_job.py:146} INFO - Task exited with return code 1
[2022-06-06 16:25:32,931] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.final_check_join_table 2022-03-01T10:00:00+00:00 [queued]>
[2022-06-06 16:25:32,941] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.final_check_join_table 2022-03-01T10:00:00+00:00 [queued]>
[2022-06-06 16:25:32,941] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 16:25:32,941] {taskinstance.py:1043} INFO - Starting attempt 1 of 3
[2022-06-06 16:25:32,942] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 16:25:32,951] {taskinstance.py:1063} INFO - Executing <Task(BigQueryCheckOperator): final_check_join_table> on 2022-03-01T10:00:00+00:00
[2022-06-06 16:25:32,955] {standard_task_runner.py:52} INFO - Started process 417 to run task
[2022-06-06 16:25:32,958] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'gbq_pipeline', 'final_check_join_table', '2022-03-01T10:00:00+00:00', '--job-id', '438', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/gbq_pipeline.py', '--cfg-path', '/tmp/tmpcw7tlzgn', '--error-file', '/tmp/tmpxci3j8mm']
[2022-06-06 16:25:32,959] {standard_task_runner.py:77} INFO - Job 438: Subtask final_check_join_table
[2022-06-06 16:25:32,991] {logging_mixin.py:104} INFO - Running <TaskInstance: gbq_pipeline.final_check_join_table 2022-03-01T10:00:00+00:00 [running]> on host c40819a450e3
[2022-06-06 16:25:33,021] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=airflow@airflow.com
AIRFLOW_CTX_DAG_OWNER=vanmai-airflow
AIRFLOW_CTX_DAG_ID=gbq_pipeline
AIRFLOW_CTX_TASK_ID=final_check_join_table
AIRFLOW_CTX_EXECUTION_DATE=2022-03-01T10:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-01T10:00:00+00:00
[2022-06-06 16:25:33,022] {sql.py:87} INFO - Executing SQL check: 
    SELECT "20220301" =
        (
        SELECT max(date)
        FROM `airflow-project-352316.github_curated.github_hackernews_join`
        )
    
[2022-06-06 16:25:33,030] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:120 DeprecationWarning: This method will be deprecated. Please use `BigQueryHook.get_client` method
[2022-06-06 16:25:33,485] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:2052 DeprecationWarning: This method is deprecated. Please use `BigQueryHook.insert_job` method.
[2022-06-06 16:25:33,486] {bigquery.py:1510} INFO - Inserting job airflow_1654532733486368_f01443e709b4b479ef0cdf08a32ea191
[2022-06-06 16:25:35,276] {sql.py:90} INFO - Record: [None]
[2022-06-06 16:25:35,283] {taskinstance.py:1455} ERROR - Test failed.
Query:

    SELECT "20220301" =
        (
        SELECT max(date)
        FROM `airflow-project-352316.github_curated.github_hackernews_join`
        )
    
Results:
[None]
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1112, in _run_raw_task
    self._prepare_and_execute_task_with_callbacks(context, task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1285, in _prepare_and_execute_task_with_callbacks
    result = self._execute_task(context, task_copy)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1315, in _execute_task
    result = task_copy.execute(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/sql.py", line 94, in execute
    raise AirflowException(f"Test failed.\nQuery:\n{self.sql}\nResults:\n{records!s}")
airflow.exceptions.AirflowException: Test failed.
Query:

    SELECT "20220301" =
        (
        SELECT max(date)
        FROM `airflow-project-352316.github_curated.github_hackernews_join`
        )
    
Results:
[None]
[2022-06-06 16:25:35,285] {taskinstance.py:1503} INFO - Marking task as UP_FOR_RETRY. dag_id=gbq_pipeline, task_id=final_check_join_table, execution_date=20220301T100000, start_date=20220606T162532, end_date=20220606T162535
[2022-06-06 16:25:35,338] {local_task_job.py:146} INFO - Task exited with return code 1
[2022-06-06 16:56:06,126] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.final_check_join_table 2022-03-01T10:00:00+00:00 [queued]>
[2022-06-06 16:56:06,135] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.final_check_join_table 2022-03-01T10:00:00+00:00 [queued]>
[2022-06-06 16:56:06,136] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 16:56:06,136] {taskinstance.py:1043} INFO - Starting attempt 1 of 3
[2022-06-06 16:56:06,137] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 16:56:06,147] {taskinstance.py:1063} INFO - Executing <Task(BigQueryCheckOperator): final_check_join_table> on 2022-03-01T10:00:00+00:00
[2022-06-06 16:56:06,151] {standard_task_runner.py:52} INFO - Started process 509 to run task
[2022-06-06 16:56:06,154] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'gbq_pipeline', 'final_check_join_table', '2022-03-01T10:00:00+00:00', '--job-id', '468', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/gbq_pipeline.py', '--cfg-path', '/tmp/tmptljiprso', '--error-file', '/tmp/tmp15jd4h_2']
[2022-06-06 16:56:06,156] {standard_task_runner.py:77} INFO - Job 468: Subtask final_check_join_table
[2022-06-06 16:56:06,187] {logging_mixin.py:104} INFO - Running <TaskInstance: gbq_pipeline.final_check_join_table 2022-03-01T10:00:00+00:00 [running]> on host c40819a450e3
[2022-06-06 16:56:06,217] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=airflow@airflow.com
AIRFLOW_CTX_DAG_OWNER=vanmai-airflow
AIRFLOW_CTX_DAG_ID=gbq_pipeline
AIRFLOW_CTX_TASK_ID=final_check_join_table
AIRFLOW_CTX_EXECUTION_DATE=2022-03-01T10:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-01T10:00:00+00:00
[2022-06-06 16:56:06,218] {sql.py:87} INFO - Executing SQL check: 
    SELECT "20220301" =
        (
        SELECT max(date)
        FROM `airflow-project-352316.github_curated.github_hackernews_join`
        )
    
[2022-06-06 16:56:06,226] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:120 DeprecationWarning: This method will be deprecated. Please use `BigQueryHook.get_client` method
[2022-06-06 16:56:06,711] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:2052 DeprecationWarning: This method is deprecated. Please use `BigQueryHook.insert_job` method.
[2022-06-06 16:56:06,712] {bigquery.py:1510} INFO - Inserting job airflow_1654534566712203_f01443e709b4b479ef0cdf08a32ea191
[2022-06-06 16:56:08,370] {sql.py:90} INFO - Record: [None]
[2022-06-06 16:56:08,381] {taskinstance.py:1455} ERROR - Test failed.
Query:

    SELECT "20220301" =
        (
        SELECT max(date)
        FROM `airflow-project-352316.github_curated.github_hackernews_join`
        )
    
Results:
[None]
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1112, in _run_raw_task
    self._prepare_and_execute_task_with_callbacks(context, task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1285, in _prepare_and_execute_task_with_callbacks
    result = self._execute_task(context, task_copy)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1315, in _execute_task
    result = task_copy.execute(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/sql.py", line 94, in execute
    raise AirflowException(f"Test failed.\nQuery:\n{self.sql}\nResults:\n{records!s}")
airflow.exceptions.AirflowException: Test failed.
Query:

    SELECT "20220301" =
        (
        SELECT max(date)
        FROM `airflow-project-352316.github_curated.github_hackernews_join`
        )
    
Results:
[None]
[2022-06-06 16:56:08,382] {taskinstance.py:1503} INFO - Marking task as UP_FOR_RETRY. dag_id=gbq_pipeline, task_id=final_check_join_table, execution_date=20220301T100000, start_date=20220606T165606, end_date=20220606T165608
[2022-06-06 16:56:08,415] {local_task_job.py:146} INFO - Task exited with return code 1
[2022-06-06 16:57:40,329] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.final_check_join_table 2022-03-01T10:00:00+00:00 [queued]>
[2022-06-06 16:57:40,338] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.final_check_join_table 2022-03-01T10:00:00+00:00 [queued]>
[2022-06-06 16:57:40,338] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 16:57:40,339] {taskinstance.py:1043} INFO - Starting attempt 1 of 3
[2022-06-06 16:57:40,339] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 16:57:40,349] {taskinstance.py:1063} INFO - Executing <Task(BigQueryCheckOperator): final_check_join_table> on 2022-03-01T10:00:00+00:00
[2022-06-06 16:57:40,353] {standard_task_runner.py:52} INFO - Started process 593 to run task
[2022-06-06 16:57:40,356] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'gbq_pipeline', 'final_check_join_table', '2022-03-01T10:00:00+00:00', '--job-id', '497', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/gbq_pipeline.py', '--cfg-path', '/tmp/tmprnma5ewt', '--error-file', '/tmp/tmpwbqmrxue']
[2022-06-06 16:57:40,358] {standard_task_runner.py:77} INFO - Job 497: Subtask final_check_join_table
[2022-06-06 16:57:40,390] {logging_mixin.py:104} INFO - Running <TaskInstance: gbq_pipeline.final_check_join_table 2022-03-01T10:00:00+00:00 [running]> on host c40819a450e3
[2022-06-06 16:57:40,419] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=airflow@airflow.com
AIRFLOW_CTX_DAG_OWNER=vanmai-airflow
AIRFLOW_CTX_DAG_ID=gbq_pipeline
AIRFLOW_CTX_TASK_ID=final_check_join_table
AIRFLOW_CTX_EXECUTION_DATE=2022-03-01T10:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-01T10:00:00+00:00
[2022-06-06 16:57:40,421] {sql.py:87} INFO - Executing SQL check: 
    SELECT "20220301" =
        (
        SELECT max(date)
        FROM `airflow-project-352316.github_curated.github_hackernews_join`
        )
    
[2022-06-06 16:57:40,429] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:120 DeprecationWarning: This method will be deprecated. Please use `BigQueryHook.get_client` method
[2022-06-06 16:57:40,854] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:2052 DeprecationWarning: This method is deprecated. Please use `BigQueryHook.insert_job` method.
[2022-06-06 16:57:40,855] {bigquery.py:1510} INFO - Inserting job airflow_1654534660854922_f01443e709b4b479ef0cdf08a32ea191
[2022-06-06 16:57:42,276] {sql.py:90} INFO - Record: [True]
[2022-06-06 16:57:42,276] {sql.py:96} INFO - Success.
[2022-06-06 16:57:42,286] {taskinstance.py:1166} INFO - Marking task as SUCCESS. dag_id=gbq_pipeline, task_id=final_check_join_table, execution_date=20220301T100000, start_date=20220606T165740, end_date=20220606T165742
[2022-06-06 16:57:42,302] {taskinstance.py:1220} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-06 16:57:42,336] {local_task_job.py:146} INFO - Task exited with return code 0
[2022-06-06 16:59:46,450] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.final_check_join_table 2022-03-01T10:00:00+00:00 [queued]>
[2022-06-06 16:59:46,459] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.final_check_join_table 2022-03-01T10:00:00+00:00 [queued]>
[2022-06-06 16:59:46,459] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 16:59:46,460] {taskinstance.py:1043} INFO - Starting attempt 1 of 3
[2022-06-06 16:59:46,460] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 16:59:46,471] {taskinstance.py:1063} INFO - Executing <Task(BigQueryCheckOperator): final_check_join_table> on 2022-03-01T10:00:00+00:00
[2022-06-06 16:59:46,475] {standard_task_runner.py:52} INFO - Started process 693 to run task
[2022-06-06 16:59:46,478] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'gbq_pipeline', 'final_check_join_table', '2022-03-01T10:00:00+00:00', '--job-id', '530', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/gbq_pipeline.py', '--cfg-path', '/tmp/tmpy1g__ll4', '--error-file', '/tmp/tmpx0f6jfmn']
[2022-06-06 16:59:46,480] {standard_task_runner.py:77} INFO - Job 530: Subtask final_check_join_table
[2022-06-06 16:59:46,510] {logging_mixin.py:104} INFO - Running <TaskInstance: gbq_pipeline.final_check_join_table 2022-03-01T10:00:00+00:00 [running]> on host c40819a450e3
[2022-06-06 16:59:46,539] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=airflow@airflow.com
AIRFLOW_CTX_DAG_OWNER=vanmai-airflow
AIRFLOW_CTX_DAG_ID=gbq_pipeline
AIRFLOW_CTX_TASK_ID=final_check_join_table
AIRFLOW_CTX_EXECUTION_DATE=2022-03-01T10:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-01T10:00:00+00:00
[2022-06-06 16:59:46,541] {sql.py:87} INFO - Executing SQL check: 
    SELECT "20220301" =
        (
        SELECT max(date)
        FROM `airflow-project-352316.github_curated.github_hackernews_join`
        )
    
[2022-06-06 16:59:46,548] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:120 DeprecationWarning: This method will be deprecated. Please use `BigQueryHook.get_client` method
[2022-06-06 16:59:46,920] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:2052 DeprecationWarning: This method is deprecated. Please use `BigQueryHook.insert_job` method.
[2022-06-06 16:59:46,921] {bigquery.py:1510} INFO - Inserting job airflow_1654534786921011_f01443e709b4b479ef0cdf08a32ea191
[2022-06-06 16:59:48,411] {sql.py:90} INFO - Record: [True]
[2022-06-06 16:59:48,411] {sql.py:96} INFO - Success.
[2022-06-06 16:59:48,421] {taskinstance.py:1166} INFO - Marking task as SUCCESS. dag_id=gbq_pipeline, task_id=final_check_join_table, execution_date=20220301T100000, start_date=20220606T165946, end_date=20220606T165948
[2022-06-06 16:59:48,438] {taskinstance.py:1220} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-06 16:59:48,461] {local_task_job.py:146} INFO - Task exited with return code 0
