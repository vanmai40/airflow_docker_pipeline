[2022-06-06 15:23:35,157] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.check_hackernews 2022-03-06T10:00:00+00:00 [queued]>
[2022-06-06 15:23:35,177] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.check_hackernews 2022-03-06T10:00:00+00:00 [queued]>
[2022-06-06 15:23:35,178] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 15:23:35,178] {taskinstance.py:1043} INFO - Starting attempt 1 of 3
[2022-06-06 15:23:35,178] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 15:23:35,186] {taskinstance.py:1063} INFO - Executing <Task(BigQueryCheckOperator): check_hackernews> on 2022-03-06T10:00:00+00:00
[2022-06-06 15:23:35,192] {standard_task_runner.py:52} INFO - Started process 266 to run task
[2022-06-06 15:23:35,195] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'gbq_pipeline', 'check_hackernews', '2022-03-06T10:00:00+00:00', '--job-id', '387', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/gbq_pipeline.py', '--cfg-path', '/tmp/tmpp_qu050j', '--error-file', '/tmp/tmpspl8f_a6']
[2022-06-06 15:23:35,197] {standard_task_runner.py:77} INFO - Job 387: Subtask check_hackernews
[2022-06-06 15:23:35,234] {logging_mixin.py:104} INFO - Running <TaskInstance: gbq_pipeline.check_hackernews 2022-03-06T10:00:00+00:00 [running]> on host c40819a450e3
[2022-06-06 15:23:35,274] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=airflow@airflow.com
AIRFLOW_CTX_DAG_OWNER=vanmai-airflow
AIRFLOW_CTX_DAG_ID=gbq_pipeline
AIRFLOW_CTX_TASK_ID=check_hackernews
AIRFLOW_CTX_EXECUTION_DATE=2022-03-06T10:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-06T10:00:00+00:00
[2022-06-06 15:23:35,276] {sql.py:87} INFO - Executing SQL check: 
        SELECT "20220306" IN
            (
            SELECT FORMAT_TIMESTAMP("%Y%m%d", timestamp ) AS date
            FROM `bigquery-public-data.hacker_news.full`
            WHERE type = 'story'
            )
        
[2022-06-06 15:23:35,284] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:120 DeprecationWarning: This method will be deprecated. Please use `BigQueryHook.get_client` method
[2022-06-06 15:23:35,714] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:2052 DeprecationWarning: This method is deprecated. Please use `BigQueryHook.insert_job` method.
[2022-06-06 15:23:35,715] {bigquery.py:1510} INFO - Inserting job airflow_1654529015715062_934b0679343c9d7d7784d7407ecfe3cf
[2022-06-06 15:23:37,623] {sql.py:90} INFO - Record: [True]
[2022-06-06 15:23:37,623] {sql.py:96} INFO - Success.
[2022-06-06 15:23:37,631] {taskinstance.py:1166} INFO - Marking task as SUCCESS. dag_id=gbq_pipeline, task_id=check_hackernews, execution_date=20220306T100000, start_date=20220606T152335, end_date=20220606T152337
[2022-06-06 15:23:37,660] {taskinstance.py:1220} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-06 15:23:37,699] {local_task_job.py:146} INFO - Task exited with return code 0
[2022-06-06 16:25:28,201] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.check_hackernews 2022-03-06T10:00:00+00:00 [queued]>
[2022-06-06 16:25:28,217] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.check_hackernews 2022-03-06T10:00:00+00:00 [queued]>
[2022-06-06 16:25:28,217] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 16:25:28,218] {taskinstance.py:1043} INFO - Starting attempt 1 of 3
[2022-06-06 16:25:28,218] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 16:25:28,224] {taskinstance.py:1063} INFO - Executing <Task(BigQueryCheckOperator): check_hackernews> on 2022-03-06T10:00:00+00:00
[2022-06-06 16:25:28,227] {standard_task_runner.py:52} INFO - Started process 405 to run task
[2022-06-06 16:25:28,230] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'gbq_pipeline', 'check_hackernews', '2022-03-06T10:00:00+00:00', '--job-id', '434', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/gbq_pipeline.py', '--cfg-path', '/tmp/tmptbphuc6m', '--error-file', '/tmp/tmp2qc4qr8d']
[2022-06-06 16:25:28,231] {standard_task_runner.py:77} INFO - Job 434: Subtask check_hackernews
[2022-06-06 16:25:28,341] {logging_mixin.py:104} INFO - Running <TaskInstance: gbq_pipeline.check_hackernews 2022-03-06T10:00:00+00:00 [running]> on host c40819a450e3
[2022-06-06 16:25:28,369] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=airflow@airflow.com
AIRFLOW_CTX_DAG_OWNER=vanmai-airflow
AIRFLOW_CTX_DAG_ID=gbq_pipeline
AIRFLOW_CTX_TASK_ID=check_hackernews
AIRFLOW_CTX_EXECUTION_DATE=2022-03-06T10:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-06T10:00:00+00:00
[2022-06-06 16:25:28,370] {sql.py:87} INFO - Executing SQL check: 
        SELECT "20220306" IN
            (
            SELECT FORMAT_TIMESTAMP("%Y%m%d", timestamp ) AS date
            FROM `bigquery-public-data.hacker_news.full`
            WHERE type = 'story'
            )
        
[2022-06-06 16:25:28,377] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:120 DeprecationWarning: This method will be deprecated. Please use `BigQueryHook.get_client` method
[2022-06-06 16:25:28,831] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:2052 DeprecationWarning: This method is deprecated. Please use `BigQueryHook.insert_job` method.
[2022-06-06 16:25:28,832] {bigquery.py:1510} INFO - Inserting job airflow_1654532728831985_934b0679343c9d7d7784d7407ecfe3cf
[2022-06-06 16:25:30,357] {sql.py:90} INFO - Record: [True]
[2022-06-06 16:25:30,357] {sql.py:96} INFO - Success.
[2022-06-06 16:25:30,364] {taskinstance.py:1166} INFO - Marking task as SUCCESS. dag_id=gbq_pipeline, task_id=check_hackernews, execution_date=20220306T100000, start_date=20220606T162528, end_date=20220606T162530
[2022-06-06 16:25:30,389] {taskinstance.py:1220} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-06 16:25:30,408] {local_task_job.py:146} INFO - Task exited with return code 0
[2022-06-06 16:56:04,389] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.check_hackernews 2022-03-06T10:00:00+00:00 [queued]>
[2022-06-06 16:56:04,406] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.check_hackernews 2022-03-06T10:00:00+00:00 [queued]>
[2022-06-06 16:56:04,407] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 16:56:04,407] {taskinstance.py:1043} INFO - Starting attempt 1 of 3
[2022-06-06 16:56:04,408] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 16:56:04,414] {taskinstance.py:1063} INFO - Executing <Task(BigQueryCheckOperator): check_hackernews> on 2022-03-06T10:00:00+00:00
[2022-06-06 16:56:04,418] {standard_task_runner.py:52} INFO - Started process 503 to run task
[2022-06-06 16:56:04,421] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'gbq_pipeline', 'check_hackernews', '2022-03-06T10:00:00+00:00', '--job-id', '466', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/gbq_pipeline.py', '--cfg-path', '/tmp/tmppvxos1lu', '--error-file', '/tmp/tmp7a1iv817']
[2022-06-06 16:56:04,422] {standard_task_runner.py:77} INFO - Job 466: Subtask check_hackernews
[2022-06-06 16:56:04,453] {logging_mixin.py:104} INFO - Running <TaskInstance: gbq_pipeline.check_hackernews 2022-03-06T10:00:00+00:00 [running]> on host c40819a450e3
[2022-06-06 16:56:04,483] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=airflow@airflow.com
AIRFLOW_CTX_DAG_OWNER=vanmai-airflow
AIRFLOW_CTX_DAG_ID=gbq_pipeline
AIRFLOW_CTX_TASK_ID=check_hackernews
AIRFLOW_CTX_EXECUTION_DATE=2022-03-06T10:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-06T10:00:00+00:00
[2022-06-06 16:56:04,485] {sql.py:87} INFO - Executing SQL check: 
        SELECT "20220306" IN
            (
            SELECT FORMAT_TIMESTAMP("%Y%m%d", timestamp ) AS date
            FROM `bigquery-public-data.hacker_news.full`
            WHERE type = 'story'
            )
        
[2022-06-06 16:56:04,492] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:120 DeprecationWarning: This method will be deprecated. Please use `BigQueryHook.get_client` method
[2022-06-06 16:56:04,816] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:2052 DeprecationWarning: This method is deprecated. Please use `BigQueryHook.insert_job` method.
[2022-06-06 16:56:04,817] {bigquery.py:1510} INFO - Inserting job airflow_1654534564817018_934b0679343c9d7d7784d7407ecfe3cf
[2022-06-06 16:56:06,323] {sql.py:90} INFO - Record: [True]
[2022-06-06 16:56:06,323] {sql.py:96} INFO - Success.
[2022-06-06 16:56:06,332] {taskinstance.py:1166} INFO - Marking task as SUCCESS. dag_id=gbq_pipeline, task_id=check_hackernews, execution_date=20220306T100000, start_date=20220606T165604, end_date=20220606T165606
[2022-06-06 16:56:06,358] {taskinstance.py:1220} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-06 16:56:06,403] {local_task_job.py:146} INFO - Task exited with return code 0
[2022-06-06 16:58:02,780] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.check_hackernews 2022-03-06T10:00:00+00:00 [queued]>
[2022-06-06 16:58:02,799] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.check_hackernews 2022-03-06T10:00:00+00:00 [queued]>
[2022-06-06 16:58:02,800] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 16:58:02,800] {taskinstance.py:1043} INFO - Starting attempt 1 of 3
[2022-06-06 16:58:02,800] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 16:58:02,808] {taskinstance.py:1063} INFO - Executing <Task(BigQueryCheckOperator): check_hackernews> on 2022-03-06T10:00:00+00:00
[2022-06-06 16:58:02,812] {standard_task_runner.py:52} INFO - Started process 633 to run task
[2022-06-06 16:58:02,815] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'gbq_pipeline', 'check_hackernews', '2022-03-06T10:00:00+00:00', '--job-id', '509', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/gbq_pipeline.py', '--cfg-path', '/tmp/tmpft_riqrn', '--error-file', '/tmp/tmpq5708wet']
[2022-06-06 16:58:02,817] {standard_task_runner.py:77} INFO - Job 509: Subtask check_hackernews
[2022-06-06 16:58:02,853] {logging_mixin.py:104} INFO - Running <TaskInstance: gbq_pipeline.check_hackernews 2022-03-06T10:00:00+00:00 [running]> on host c40819a450e3
[2022-06-06 16:58:02,884] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=airflow@airflow.com
AIRFLOW_CTX_DAG_OWNER=vanmai-airflow
AIRFLOW_CTX_DAG_ID=gbq_pipeline
AIRFLOW_CTX_TASK_ID=check_hackernews
AIRFLOW_CTX_EXECUTION_DATE=2022-03-06T10:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-06T10:00:00+00:00
[2022-06-06 16:58:02,885] {sql.py:87} INFO - Executing SQL check: 
        SELECT "20220306" IN
            (
            SELECT FORMAT_TIMESTAMP("%Y%m%d", timestamp ) AS date
            FROM `bigquery-public-data.hacker_news.full`
            WHERE type = 'story'
            )
        
[2022-06-06 16:58:02,893] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:120 DeprecationWarning: This method will be deprecated. Please use `BigQueryHook.get_client` method
[2022-06-06 16:58:03,350] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:2052 DeprecationWarning: This method is deprecated. Please use `BigQueryHook.insert_job` method.
[2022-06-06 16:58:03,351] {bigquery.py:1510} INFO - Inserting job airflow_1654534683351291_934b0679343c9d7d7784d7407ecfe3cf
[2022-06-06 16:58:04,677] {sql.py:90} INFO - Record: [True]
[2022-06-06 16:58:04,678] {sql.py:96} INFO - Success.
[2022-06-06 16:58:04,688] {taskinstance.py:1166} INFO - Marking task as SUCCESS. dag_id=gbq_pipeline, task_id=check_hackernews, execution_date=20220306T100000, start_date=20220606T165802, end_date=20220606T165804
[2022-06-06 16:58:04,712] {taskinstance.py:1220} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-06 16:58:04,718] {local_task_job.py:146} INFO - Task exited with return code 0
[2022-06-06 16:59:54,552] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.check_hackernews 2022-03-06T10:00:00+00:00 [queued]>
[2022-06-06 16:59:54,572] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.check_hackernews 2022-03-06T10:00:00+00:00 [queued]>
[2022-06-06 16:59:54,573] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 16:59:54,573] {taskinstance.py:1043} INFO - Starting attempt 1 of 3
[2022-06-06 16:59:54,574] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 16:59:54,598] {taskinstance.py:1063} INFO - Executing <Task(BigQueryCheckOperator): check_hackernews> on 2022-03-06T10:00:00+00:00
[2022-06-06 16:59:54,604] {standard_task_runner.py:52} INFO - Started process 735 to run task
[2022-06-06 16:59:54,611] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'gbq_pipeline', 'check_hackernews', '2022-03-06T10:00:00+00:00', '--job-id', '544', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/gbq_pipeline.py', '--cfg-path', '/tmp/tmpq5386wv0', '--error-file', '/tmp/tmpon_dwpet']
[2022-06-06 16:59:54,614] {standard_task_runner.py:77} INFO - Job 544: Subtask check_hackernews
[2022-06-06 16:59:54,674] {logging_mixin.py:104} INFO - Running <TaskInstance: gbq_pipeline.check_hackernews 2022-03-06T10:00:00+00:00 [running]> on host c40819a450e3
[2022-06-06 16:59:54,746] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=airflow@airflow.com
AIRFLOW_CTX_DAG_OWNER=vanmai-airflow
AIRFLOW_CTX_DAG_ID=gbq_pipeline
AIRFLOW_CTX_TASK_ID=check_hackernews
AIRFLOW_CTX_EXECUTION_DATE=2022-03-06T10:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-06T10:00:00+00:00
[2022-06-06 16:59:54,748] {sql.py:87} INFO - Executing SQL check: 
        SELECT "20220306" IN
            (
            SELECT FORMAT_TIMESTAMP("%Y%m%d", timestamp ) AS date
            FROM `bigquery-public-data.hacker_news.full`
            WHERE type = 'story'
            )
        
[2022-06-06 16:59:54,758] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:120 DeprecationWarning: This method will be deprecated. Please use `BigQueryHook.get_client` method
[2022-06-06 16:59:55,296] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:2052 DeprecationWarning: This method is deprecated. Please use `BigQueryHook.insert_job` method.
[2022-06-06 16:59:55,297] {bigquery.py:1510} INFO - Inserting job airflow_1654534795296983_934b0679343c9d7d7784d7407ecfe3cf
[2022-06-06 16:59:56,711] {sql.py:90} INFO - Record: [True]
[2022-06-06 16:59:56,712] {sql.py:96} INFO - Success.
[2022-06-06 16:59:56,720] {taskinstance.py:1166} INFO - Marking task as SUCCESS. dag_id=gbq_pipeline, task_id=check_hackernews, execution_date=20220306T100000, start_date=20220606T165954, end_date=20220606T165956
[2022-06-06 16:59:56,786] {taskinstance.py:1220} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-06 16:59:56,793] {local_task_job.py:146} INFO - Task exited with return code 0
