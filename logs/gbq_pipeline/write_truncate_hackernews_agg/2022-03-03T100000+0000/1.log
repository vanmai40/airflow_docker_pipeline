[2022-06-06 15:23:30,896] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.write_truncate_hackernews_agg 2022-03-03T10:00:00+00:00 [queued]>
[2022-06-06 15:23:30,919] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.write_truncate_hackernews_agg 2022-03-03T10:00:00+00:00 [queued]>
[2022-06-06 15:23:30,919] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 15:23:30,920] {taskinstance.py:1043} INFO - Starting attempt 1 of 3
[2022-06-06 15:23:30,920] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 15:23:30,928] {taskinstance.py:1063} INFO - Executing <Task(BigQueryOperator): write_truncate_hackernews_agg> on 2022-03-03T10:00:00+00:00
[2022-06-06 15:23:30,933] {standard_task_runner.py:52} INFO - Started process 253 to run task
[2022-06-06 15:23:30,936] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'gbq_pipeline', 'write_truncate_hackernews_agg', '2022-03-03T10:00:00+00:00', '--job-id', '382', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/gbq_pipeline.py', '--cfg-path', '/tmp/tmp8x5ype1q', '--error-file', '/tmp/tmp0do3x6cg']
[2022-06-06 15:23:30,938] {standard_task_runner.py:77} INFO - Job 382: Subtask write_truncate_hackernews_agg
[2022-06-06 15:23:30,975] {logging_mixin.py:104} INFO - Running <TaskInstance: gbq_pipeline.write_truncate_hackernews_agg 2022-03-03T10:00:00+00:00 [running]> on host c40819a450e3
[2022-06-06 15:23:31,012] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=airflow@airflow.com
AIRFLOW_CTX_DAG_OWNER=vanmai-airflow
AIRFLOW_CTX_DAG_ID=gbq_pipeline
AIRFLOW_CTX_TASK_ID=write_truncate_hackernews_agg
AIRFLOW_CTX_EXECUTION_DATE=2022-03-03T10:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-03T10:00:00+00:00
[2022-06-06 15:23:31,014] {bigquery.py:680} INFO - Executing: 
    SELECT
      FORMAT_TIMESTAMP("%Y%m%d", timestamp) AS date,
      `by` AS user,
      id as story_id,
      REGEXP_EXTRACT(url, "(https?://github.com/[^/]*/[^/#?]*)") as github_repo,
      type,
      length(text) length,
      SUM(score) as score
    FROM
      `bigquery-public-data.hacker_news.full`
    WHERE TRUE
      AND FORMAT_TIMESTAMP("%Y%m%d", timestamp) = '20220303'
      AND url LIKE '%https://github.com%'
      AND url NOT LIKE '%github.com/blog/%'
    GROUP BY 1,2,3,4,5,6
    
[2022-06-06 15:23:31,023] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:2052 DeprecationWarning: This method is deprecated. Please use `BigQueryHook.insert_job` method.
[2022-06-06 15:23:31,030] {bigquery.py:1510} INFO - Inserting job airflow_1654529011029762_1c0dfc55f01b21df72379f98a3999069
[2022-06-06 15:23:34,467] {taskinstance.py:1166} INFO - Marking task as SUCCESS. dag_id=gbq_pipeline, task_id=write_truncate_hackernews_agg, execution_date=20220303T100000, start_date=20220606T152330, end_date=20220606T152334
[2022-06-06 15:23:34,574] {taskinstance.py:1220} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-06 15:23:34,604] {local_task_job.py:146} INFO - Task exited with return code 0
[2022-06-06 16:25:24,622] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.write_truncate_hackernews_agg 2022-03-03T10:00:00+00:00 [queued]>
[2022-06-06 16:25:24,640] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.write_truncate_hackernews_agg 2022-03-03T10:00:00+00:00 [queued]>
[2022-06-06 16:25:24,640] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 16:25:24,640] {taskinstance.py:1043} INFO - Starting attempt 1 of 3
[2022-06-06 16:25:24,641] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 16:25:24,648] {taskinstance.py:1063} INFO - Executing <Task(BigQueryOperator): write_truncate_hackernews_agg> on 2022-03-03T10:00:00+00:00
[2022-06-06 16:25:24,651] {standard_task_runner.py:52} INFO - Started process 393 to run task
[2022-06-06 16:25:24,654] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'gbq_pipeline', 'write_truncate_hackernews_agg', '2022-03-03T10:00:00+00:00', '--job-id', '430', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/gbq_pipeline.py', '--cfg-path', '/tmp/tmp22oktdmu', '--error-file', '/tmp/tmpovwe4dyl']
[2022-06-06 16:25:24,656] {standard_task_runner.py:77} INFO - Job 430: Subtask write_truncate_hackernews_agg
[2022-06-06 16:25:24,690] {logging_mixin.py:104} INFO - Running <TaskInstance: gbq_pipeline.write_truncate_hackernews_agg 2022-03-03T10:00:00+00:00 [running]> on host c40819a450e3
[2022-06-06 16:25:24,722] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=airflow@airflow.com
AIRFLOW_CTX_DAG_OWNER=vanmai-airflow
AIRFLOW_CTX_DAG_ID=gbq_pipeline
AIRFLOW_CTX_TASK_ID=write_truncate_hackernews_agg
AIRFLOW_CTX_EXECUTION_DATE=2022-03-03T10:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-03T10:00:00+00:00
[2022-06-06 16:25:24,723] {bigquery.py:680} INFO - Executing: 
    SELECT
      FORMAT_TIMESTAMP("%Y%m%d", timestamp) AS date,
      `by` AS user,
      id as story_id,
      REGEXP_EXTRACT(url, "(https?://github.com/[^/]*/[^/#?]*)") as github_repo,
      type,
      length(text) length,
      SUM(score) as score
    FROM
      `bigquery-public-data.hacker_news.full`
    WHERE TRUE
      AND FORMAT_TIMESTAMP("%Y%m%d", timestamp) = '20220303'
      AND url LIKE '%https://github.com%'
      AND url NOT LIKE '%github.com/blog/%'
    GROUP BY 1,2,3,4,5,6
    
[2022-06-06 16:25:24,731] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:2052 DeprecationWarning: This method is deprecated. Please use `BigQueryHook.insert_job` method.
[2022-06-06 16:25:24,738] {bigquery.py:1510} INFO - Inserting job airflow_1654532724737816_1c0dfc55f01b21df72379f98a3999069
[2022-06-06 16:25:28,774] {taskinstance.py:1166} INFO - Marking task as SUCCESS. dag_id=gbq_pipeline, task_id=write_truncate_hackernews_agg, execution_date=20220303T100000, start_date=20220606T162524, end_date=20220606T162528
[2022-06-06 16:25:28,804] {taskinstance.py:1220} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-06 16:25:28,844] {local_task_job.py:146} INFO - Task exited with return code 0
[2022-06-06 16:56:01,214] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.write_truncate_hackernews_agg 2022-03-03T10:00:00+00:00 [queued]>
[2022-06-06 16:56:01,233] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.write_truncate_hackernews_agg 2022-03-03T10:00:00+00:00 [queued]>
[2022-06-06 16:56:01,234] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 16:56:01,234] {taskinstance.py:1043} INFO - Starting attempt 1 of 3
[2022-06-06 16:56:01,234] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 16:56:01,240] {taskinstance.py:1063} INFO - Executing <Task(BigQueryOperator): write_truncate_hackernews_agg> on 2022-03-03T10:00:00+00:00
[2022-06-06 16:56:01,244] {standard_task_runner.py:52} INFO - Started process 497 to run task
[2022-06-06 16:56:01,247] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'gbq_pipeline', 'write_truncate_hackernews_agg', '2022-03-03T10:00:00+00:00', '--job-id', '464', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/gbq_pipeline.py', '--cfg-path', '/tmp/tmpbfay1dbc', '--error-file', '/tmp/tmpvl82omsr']
[2022-06-06 16:56:01,248] {standard_task_runner.py:77} INFO - Job 464: Subtask write_truncate_hackernews_agg
[2022-06-06 16:56:01,284] {logging_mixin.py:104} INFO - Running <TaskInstance: gbq_pipeline.write_truncate_hackernews_agg 2022-03-03T10:00:00+00:00 [running]> on host c40819a450e3
[2022-06-06 16:56:01,314] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=airflow@airflow.com
AIRFLOW_CTX_DAG_OWNER=vanmai-airflow
AIRFLOW_CTX_DAG_ID=gbq_pipeline
AIRFLOW_CTX_TASK_ID=write_truncate_hackernews_agg
AIRFLOW_CTX_EXECUTION_DATE=2022-03-03T10:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-03T10:00:00+00:00
[2022-06-06 16:56:01,316] {bigquery.py:680} INFO - Executing: 
    SELECT
      FORMAT_TIMESTAMP("%Y%m%d", timestamp) AS date,
      `by` AS user,
      id as story_id,
      REGEXP_EXTRACT(url, "(https?://github.com/[^/]*/[^/#?]*)") as github_repo,
      type,
      length(text) length,
      SUM(score) as score
    FROM
      `bigquery-public-data.hacker_news.full`
    WHERE TRUE
      AND FORMAT_TIMESTAMP("%Y%m%d", timestamp) = '20220303'
      AND url LIKE '%https://github.com%'
      AND url NOT LIKE '%github.com/blog/%'
    GROUP BY 1,2,3,4,5,6
    
[2022-06-06 16:56:01,324] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:2052 DeprecationWarning: This method is deprecated. Please use `BigQueryHook.insert_job` method.
[2022-06-06 16:56:01,330] {bigquery.py:1510} INFO - Inserting job airflow_1654534561329720_1c0dfc55f01b21df72379f98a3999069
[2022-06-06 16:56:04,711] {taskinstance.py:1166} INFO - Marking task as SUCCESS. dag_id=gbq_pipeline, task_id=write_truncate_hackernews_agg, execution_date=20220303T100000, start_date=20220606T165601, end_date=20220606T165604
[2022-06-06 16:56:04,740] {taskinstance.py:1220} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-06 16:56:04,756] {local_task_job.py:146} INFO - Task exited with return code 0
[2022-06-06 16:57:43,636] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.write_truncate_hackernews_agg 2022-03-03T10:00:00+00:00 [queued]>
[2022-06-06 16:57:43,654] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.write_truncate_hackernews_agg 2022-03-03T10:00:00+00:00 [queued]>
[2022-06-06 16:57:43,654] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 16:57:43,655] {taskinstance.py:1043} INFO - Starting attempt 1 of 3
[2022-06-06 16:57:43,655] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 16:57:43,662] {taskinstance.py:1063} INFO - Executing <Task(BigQueryOperator): write_truncate_hackernews_agg> on 2022-03-03T10:00:00+00:00
[2022-06-06 16:57:43,666] {standard_task_runner.py:52} INFO - Started process 597 to run task
[2022-06-06 16:57:43,669] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'gbq_pipeline', 'write_truncate_hackernews_agg', '2022-03-03T10:00:00+00:00', '--job-id', '498', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/gbq_pipeline.py', '--cfg-path', '/tmp/tmp_wt2ran5', '--error-file', '/tmp/tmpa_cm3tu3']
[2022-06-06 16:57:43,671] {standard_task_runner.py:77} INFO - Job 498: Subtask write_truncate_hackernews_agg
[2022-06-06 16:57:43,704] {logging_mixin.py:104} INFO - Running <TaskInstance: gbq_pipeline.write_truncate_hackernews_agg 2022-03-03T10:00:00+00:00 [running]> on host c40819a450e3
[2022-06-06 16:57:43,734] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=airflow@airflow.com
AIRFLOW_CTX_DAG_OWNER=vanmai-airflow
AIRFLOW_CTX_DAG_ID=gbq_pipeline
AIRFLOW_CTX_TASK_ID=write_truncate_hackernews_agg
AIRFLOW_CTX_EXECUTION_DATE=2022-03-03T10:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-03T10:00:00+00:00
[2022-06-06 16:57:43,735] {bigquery.py:680} INFO - Executing: 
    SELECT
      FORMAT_TIMESTAMP("%Y%m%d", timestamp) AS date,
      `by` AS user,
      id as story_id,
      REGEXP_EXTRACT(url, "(https?://github.com/[^/]*/[^/#?]*)") as github_repo,
      type,
      length(text) length,
      SUM(score) as score
    FROM
      `bigquery-public-data.hacker_news.full`
    WHERE TRUE
      AND FORMAT_TIMESTAMP("%Y%m%d", timestamp) = '20220303'
      AND url LIKE '%https://github.com%'
      AND url NOT LIKE '%github.com/blog/%'
    GROUP BY 1,2,3,4,5,6
    
[2022-06-06 16:57:43,743] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:2052 DeprecationWarning: This method is deprecated. Please use `BigQueryHook.insert_job` method.
[2022-06-06 16:57:43,750] {bigquery.py:1510} INFO - Inserting job airflow_1654534663750153_1c0dfc55f01b21df72379f98a3999069
[2022-06-06 16:57:46,978] {taskinstance.py:1166} INFO - Marking task as SUCCESS. dag_id=gbq_pipeline, task_id=write_truncate_hackernews_agg, execution_date=20220303T100000, start_date=20220606T165743, end_date=20220606T165746
[2022-06-06 16:57:47,094] {taskinstance.py:1220} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-06 16:57:47,140] {local_task_job.py:146} INFO - Task exited with return code 0
[2022-06-06 16:59:49,488] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.write_truncate_hackernews_agg 2022-03-03T10:00:00+00:00 [queued]>
[2022-06-06 16:59:49,497] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.write_truncate_hackernews_agg 2022-03-03T10:00:00+00:00 [queued]>
[2022-06-06 16:59:49,497] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 16:59:49,497] {taskinstance.py:1043} INFO - Starting attempt 1 of 3
[2022-06-06 16:59:49,498] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 16:59:49,507] {taskinstance.py:1063} INFO - Executing <Task(BigQueryOperator): write_truncate_hackernews_agg> on 2022-03-03T10:00:00+00:00
[2022-06-06 16:59:49,512] {standard_task_runner.py:52} INFO - Started process 696 to run task
[2022-06-06 16:59:49,514] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'gbq_pipeline', 'write_truncate_hackernews_agg', '2022-03-03T10:00:00+00:00', '--job-id', '531', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/gbq_pipeline.py', '--cfg-path', '/tmp/tmp_1aoi324', '--error-file', '/tmp/tmpfen1ya2c']
[2022-06-06 16:59:49,517] {standard_task_runner.py:77} INFO - Job 531: Subtask write_truncate_hackernews_agg
[2022-06-06 16:59:49,549] {logging_mixin.py:104} INFO - Running <TaskInstance: gbq_pipeline.write_truncate_hackernews_agg 2022-03-03T10:00:00+00:00 [running]> on host c40819a450e3
[2022-06-06 16:59:49,577] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=airflow@airflow.com
AIRFLOW_CTX_DAG_OWNER=vanmai-airflow
AIRFLOW_CTX_DAG_ID=gbq_pipeline
AIRFLOW_CTX_TASK_ID=write_truncate_hackernews_agg
AIRFLOW_CTX_EXECUTION_DATE=2022-03-03T10:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-03T10:00:00+00:00
[2022-06-06 16:59:49,579] {bigquery.py:680} INFO - Executing: 
    SELECT
      FORMAT_TIMESTAMP("%Y%m%d", timestamp) AS date,
      `by` AS user,
      id as story_id,
      REGEXP_EXTRACT(url, "(https?://github.com/[^/]*/[^/#?]*)") as github_repo,
      type,
      length(text) length,
      SUM(score) as score
    FROM
      `bigquery-public-data.hacker_news.full`
    WHERE TRUE
      AND FORMAT_TIMESTAMP("%Y%m%d", timestamp) = '20220303'
      AND url LIKE '%https://github.com%'
      AND url NOT LIKE '%github.com/blog/%'
    GROUP BY 1,2,3,4,5,6
    
[2022-06-06 16:59:49,586] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:2052 DeprecationWarning: This method is deprecated. Please use `BigQueryHook.insert_job` method.
[2022-06-06 16:59:49,593] {bigquery.py:1510} INFO - Inserting job airflow_1654534789593102_1c0dfc55f01b21df72379f98a3999069
[2022-06-06 16:59:53,095] {taskinstance.py:1166} INFO - Marking task as SUCCESS. dag_id=gbq_pipeline, task_id=write_truncate_hackernews_agg, execution_date=20220303T100000, start_date=20220606T165949, end_date=20220606T165953
[2022-06-06 16:59:53,214] {taskinstance.py:1220} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-06 16:59:53,268] {local_task_job.py:146} INFO - Task exited with return code 0
