[2022-06-06 15:23:51,165] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.write_truncate_hackernews_agg 2022-03-07T10:00:00+00:00 [queued]>
[2022-06-06 15:23:51,184] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.write_truncate_hackernews_agg 2022-03-07T10:00:00+00:00 [queued]>
[2022-06-06 15:23:51,184] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 15:23:51,184] {taskinstance.py:1043} INFO - Starting attempt 1 of 3
[2022-06-06 15:23:51,185] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 15:23:51,191] {taskinstance.py:1063} INFO - Executing <Task(BigQueryOperator): write_truncate_hackernews_agg> on 2022-03-07T10:00:00+00:00
[2022-06-06 15:23:51,270] {standard_task_runner.py:52} INFO - Started process 306 to run task
[2022-06-06 15:23:51,273] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'gbq_pipeline', 'write_truncate_hackernews_agg', '2022-03-07T10:00:00+00:00', '--job-id', '401', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/gbq_pipeline.py', '--cfg-path', '/tmp/tmpyb7sip5q', '--error-file', '/tmp/tmp59ptr672']
[2022-06-06 15:23:51,275] {standard_task_runner.py:77} INFO - Job 401: Subtask write_truncate_hackernews_agg
[2022-06-06 15:23:51,309] {logging_mixin.py:104} INFO - Running <TaskInstance: gbq_pipeline.write_truncate_hackernews_agg 2022-03-07T10:00:00+00:00 [running]> on host c40819a450e3
[2022-06-06 15:23:51,339] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=airflow@airflow.com
AIRFLOW_CTX_DAG_OWNER=vanmai-airflow
AIRFLOW_CTX_DAG_ID=gbq_pipeline
AIRFLOW_CTX_TASK_ID=write_truncate_hackernews_agg
AIRFLOW_CTX_EXECUTION_DATE=2022-03-07T10:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-07T10:00:00+00:00
[2022-06-06 15:23:51,340] {bigquery.py:680} INFO - Executing: 
    SELECT
      FORMAT_TIMESTAMP("%Y%m%d", timestamp) AS date,
      `by` AS user,
      id as story_id,
      REGEXP_EXTRACT(url, "(https?://github.com/[^/]*/[^/#?]*)") as github_repo,
      type,
      length(text) length,
      SUM(score) as score
    FROM
      `bigquery-public-data.hacker_news.full`
    WHERE TRUE
      AND FORMAT_TIMESTAMP("%Y%m%d", timestamp) = '20220307'
      AND url LIKE '%https://github.com%'
      AND url NOT LIKE '%github.com/blog/%'
    GROUP BY 1,2,3,4,5,6
    
[2022-06-06 15:23:51,348] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:2052 DeprecationWarning: This method is deprecated. Please use `BigQueryHook.insert_job` method.
[2022-06-06 15:23:51,354] {bigquery.py:1510} INFO - Inserting job airflow_1654529031353832_47296cbf7f9df7d8ed633d4f8cc0123a
[2022-06-06 15:23:56,296] {taskinstance.py:1166} INFO - Marking task as SUCCESS. dag_id=gbq_pipeline, task_id=write_truncate_hackernews_agg, execution_date=20220307T100000, start_date=20220606T152351, end_date=20220606T152356
[2022-06-06 15:23:56,340] {taskinstance.py:1220} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-06 15:23:56,402] {local_task_job.py:146} INFO - Task exited with return code 0
[2022-06-06 16:25:47,733] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.write_truncate_hackernews_agg 2022-03-07T10:00:00+00:00 [queued]>
[2022-06-06 16:25:47,750] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.write_truncate_hackernews_agg 2022-03-07T10:00:00+00:00 [queued]>
[2022-06-06 16:25:47,750] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 16:25:47,751] {taskinstance.py:1043} INFO - Starting attempt 1 of 3
[2022-06-06 16:25:47,751] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 16:25:47,757] {taskinstance.py:1063} INFO - Executing <Task(BigQueryOperator): write_truncate_hackernews_agg> on 2022-03-07T10:00:00+00:00
[2022-06-06 16:25:47,763] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'gbq_pipeline', 'write_truncate_hackernews_agg', '2022-03-07T10:00:00+00:00', '--job-id', '450', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/gbq_pipeline.py', '--cfg-path', '/tmp/tmp_8wspeak', '--error-file', '/tmp/tmpmxgqgu3e']
[2022-06-06 16:25:47,761] {standard_task_runner.py:52} INFO - Started process 453 to run task
[2022-06-06 16:25:47,765] {standard_task_runner.py:77} INFO - Job 450: Subtask write_truncate_hackernews_agg
[2022-06-06 16:25:47,797] {logging_mixin.py:104} INFO - Running <TaskInstance: gbq_pipeline.write_truncate_hackernews_agg 2022-03-07T10:00:00+00:00 [running]> on host c40819a450e3
[2022-06-06 16:25:47,825] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=airflow@airflow.com
AIRFLOW_CTX_DAG_OWNER=vanmai-airflow
AIRFLOW_CTX_DAG_ID=gbq_pipeline
AIRFLOW_CTX_TASK_ID=write_truncate_hackernews_agg
AIRFLOW_CTX_EXECUTION_DATE=2022-03-07T10:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-07T10:00:00+00:00
[2022-06-06 16:25:47,827] {bigquery.py:680} INFO - Executing: 
    SELECT
      FORMAT_TIMESTAMP("%Y%m%d", timestamp) AS date,
      `by` AS user,
      id as story_id,
      REGEXP_EXTRACT(url, "(https?://github.com/[^/]*/[^/#?]*)") as github_repo,
      type,
      length(text) length,
      SUM(score) as score
    FROM
      `bigquery-public-data.hacker_news.full`
    WHERE TRUE
      AND FORMAT_TIMESTAMP("%Y%m%d", timestamp) = '20220307'
      AND url LIKE '%https://github.com%'
      AND url NOT LIKE '%github.com/blog/%'
    GROUP BY 1,2,3,4,5,6
    
[2022-06-06 16:25:47,834] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:2052 DeprecationWarning: This method is deprecated. Please use `BigQueryHook.insert_job` method.
[2022-06-06 16:25:47,840] {bigquery.py:1510} INFO - Inserting job airflow_1654532747840276_47296cbf7f9df7d8ed633d4f8cc0123a
[2022-06-06 16:25:51,576] {taskinstance.py:1166} INFO - Marking task as SUCCESS. dag_id=gbq_pipeline, task_id=write_truncate_hackernews_agg, execution_date=20220307T100000, start_date=20220606T162547, end_date=20220606T162551
[2022-06-06 16:25:51,606] {taskinstance.py:1220} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-06 16:25:51,641] {local_task_job.py:146} INFO - Task exited with return code 0
[2022-06-06 16:56:21,306] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.write_truncate_hackernews_agg 2022-03-07T10:00:00+00:00 [queued]>
[2022-06-06 16:56:21,322] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.write_truncate_hackernews_agg 2022-03-07T10:00:00+00:00 [queued]>
[2022-06-06 16:56:21,323] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 16:56:21,323] {taskinstance.py:1043} INFO - Starting attempt 1 of 3
[2022-06-06 16:56:21,323] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 16:56:21,329] {taskinstance.py:1063} INFO - Executing <Task(BigQueryOperator): write_truncate_hackernews_agg> on 2022-03-07T10:00:00+00:00
[2022-06-06 16:56:21,337] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'gbq_pipeline', 'write_truncate_hackernews_agg', '2022-03-07T10:00:00+00:00', '--job-id', '478', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/gbq_pipeline.py', '--cfg-path', '/tmp/tmpvrqu_4tk', '--error-file', '/tmp/tmpmx9fvkdi']
[2022-06-06 16:56:21,334] {standard_task_runner.py:52} INFO - Started process 537 to run task
[2022-06-06 16:56:21,339] {standard_task_runner.py:77} INFO - Job 478: Subtask write_truncate_hackernews_agg
[2022-06-06 16:56:21,372] {logging_mixin.py:104} INFO - Running <TaskInstance: gbq_pipeline.write_truncate_hackernews_agg 2022-03-07T10:00:00+00:00 [running]> on host c40819a450e3
[2022-06-06 16:56:21,409] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=airflow@airflow.com
AIRFLOW_CTX_DAG_OWNER=vanmai-airflow
AIRFLOW_CTX_DAG_ID=gbq_pipeline
AIRFLOW_CTX_TASK_ID=write_truncate_hackernews_agg
AIRFLOW_CTX_EXECUTION_DATE=2022-03-07T10:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-07T10:00:00+00:00
[2022-06-06 16:56:21,411] {bigquery.py:680} INFO - Executing: 
    SELECT
      FORMAT_TIMESTAMP("%Y%m%d", timestamp) AS date,
      `by` AS user,
      id as story_id,
      REGEXP_EXTRACT(url, "(https?://github.com/[^/]*/[^/#?]*)") as github_repo,
      type,
      length(text) length,
      SUM(score) as score
    FROM
      `bigquery-public-data.hacker_news.full`
    WHERE TRUE
      AND FORMAT_TIMESTAMP("%Y%m%d", timestamp) = '20220307'
      AND url LIKE '%https://github.com%'
      AND url NOT LIKE '%github.com/blog/%'
    GROUP BY 1,2,3,4,5,6
    
[2022-06-06 16:56:21,418] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:2052 DeprecationWarning: This method is deprecated. Please use `BigQueryHook.insert_job` method.
[2022-06-06 16:56:21,426] {bigquery.py:1510} INFO - Inserting job airflow_1654534581425820_47296cbf7f9df7d8ed633d4f8cc0123a
[2022-06-06 16:56:25,470] {taskinstance.py:1166} INFO - Marking task as SUCCESS. dag_id=gbq_pipeline, task_id=write_truncate_hackernews_agg, execution_date=20220307T100000, start_date=20220606T165621, end_date=20220606T165625
[2022-06-06 16:56:25,508] {taskinstance.py:1220} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-06 16:56:25,532] {local_task_job.py:146} INFO - Task exited with return code 0
[2022-06-06 16:58:13,206] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.write_truncate_hackernews_agg 2022-03-07T10:00:00+00:00 [queued]>
[2022-06-06 16:58:13,223] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.write_truncate_hackernews_agg 2022-03-07T10:00:00+00:00 [queued]>
[2022-06-06 16:58:13,224] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 16:58:13,224] {taskinstance.py:1043} INFO - Starting attempt 1 of 3
[2022-06-06 16:58:13,225] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 16:58:13,231] {taskinstance.py:1063} INFO - Executing <Task(BigQueryOperator): write_truncate_hackernews_agg> on 2022-03-07T10:00:00+00:00
[2022-06-06 16:58:13,236] {standard_task_runner.py:52} INFO - Started process 648 to run task
[2022-06-06 16:58:13,239] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'gbq_pipeline', 'write_truncate_hackernews_agg', '2022-03-07T10:00:00+00:00', '--job-id', '515', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/gbq_pipeline.py', '--cfg-path', '/tmp/tmpymye55dv', '--error-file', '/tmp/tmps9oa7av8']
[2022-06-06 16:58:13,240] {standard_task_runner.py:77} INFO - Job 515: Subtask write_truncate_hackernews_agg
[2022-06-06 16:58:13,273] {logging_mixin.py:104} INFO - Running <TaskInstance: gbq_pipeline.write_truncate_hackernews_agg 2022-03-07T10:00:00+00:00 [running]> on host c40819a450e3
[2022-06-06 16:58:13,305] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=airflow@airflow.com
AIRFLOW_CTX_DAG_OWNER=vanmai-airflow
AIRFLOW_CTX_DAG_ID=gbq_pipeline
AIRFLOW_CTX_TASK_ID=write_truncate_hackernews_agg
AIRFLOW_CTX_EXECUTION_DATE=2022-03-07T10:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-07T10:00:00+00:00
[2022-06-06 16:58:13,306] {bigquery.py:680} INFO - Executing: 
    SELECT
      FORMAT_TIMESTAMP("%Y%m%d", timestamp) AS date,
      `by` AS user,
      id as story_id,
      REGEXP_EXTRACT(url, "(https?://github.com/[^/]*/[^/#?]*)") as github_repo,
      type,
      length(text) length,
      SUM(score) as score
    FROM
      `bigquery-public-data.hacker_news.full`
    WHERE TRUE
      AND FORMAT_TIMESTAMP("%Y%m%d", timestamp) = '20220307'
      AND url LIKE '%https://github.com%'
      AND url NOT LIKE '%github.com/blog/%'
    GROUP BY 1,2,3,4,5,6
    
[2022-06-06 16:58:13,314] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:2052 DeprecationWarning: This method is deprecated. Please use `BigQueryHook.insert_job` method.
[2022-06-06 16:58:13,322] {bigquery.py:1510} INFO - Inserting job airflow_1654534693322174_47296cbf7f9df7d8ed633d4f8cc0123a
[2022-06-06 16:58:16,373] {taskinstance.py:1166} INFO - Marking task as SUCCESS. dag_id=gbq_pipeline, task_id=write_truncate_hackernews_agg, execution_date=20220307T100000, start_date=20220606T165813, end_date=20220606T165816
[2022-06-06 16:58:16,409] {taskinstance.py:1220} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-06 16:58:16,429] {local_task_job.py:146} INFO - Task exited with return code 0
[2022-06-06 16:59:57,781] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.write_truncate_hackernews_agg 2022-03-07T10:00:00+00:00 [queued]>
[2022-06-06 16:59:57,798] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: gbq_pipeline.write_truncate_hackernews_agg 2022-03-07T10:00:00+00:00 [queued]>
[2022-06-06 16:59:57,799] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 16:59:57,799] {taskinstance.py:1043} INFO - Starting attempt 1 of 3
[2022-06-06 16:59:57,799] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2022-06-06 16:59:57,815] {taskinstance.py:1063} INFO - Executing <Task(BigQueryOperator): write_truncate_hackernews_agg> on 2022-03-07T10:00:00+00:00
[2022-06-06 16:59:57,822] {standard_task_runner.py:52} INFO - Started process 767 to run task
[2022-06-06 16:59:57,826] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'gbq_pipeline', 'write_truncate_hackernews_agg', '2022-03-07T10:00:00+00:00', '--job-id', '549', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/gbq_pipeline.py', '--cfg-path', '/tmp/tmpb____zdf', '--error-file', '/tmp/tmpljq6osx1']
[2022-06-06 16:59:57,829] {standard_task_runner.py:77} INFO - Job 549: Subtask write_truncate_hackernews_agg
[2022-06-06 16:59:57,885] {logging_mixin.py:104} INFO - Running <TaskInstance: gbq_pipeline.write_truncate_hackernews_agg 2022-03-07T10:00:00+00:00 [running]> on host c40819a450e3
[2022-06-06 16:59:57,996] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=airflow@airflow.com
AIRFLOW_CTX_DAG_OWNER=vanmai-airflow
AIRFLOW_CTX_DAG_ID=gbq_pipeline
AIRFLOW_CTX_TASK_ID=write_truncate_hackernews_agg
AIRFLOW_CTX_EXECUTION_DATE=2022-03-07T10:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-03-07T10:00:00+00:00
[2022-06-06 16:59:58,000] {bigquery.py:680} INFO - Executing: 
    SELECT
      FORMAT_TIMESTAMP("%Y%m%d", timestamp) AS date,
      `by` AS user,
      id as story_id,
      REGEXP_EXTRACT(url, "(https?://github.com/[^/]*/[^/#?]*)") as github_repo,
      type,
      length(text) length,
      SUM(score) as score
    FROM
      `bigquery-public-data.hacker_news.full`
    WHERE TRUE
      AND FORMAT_TIMESTAMP("%Y%m%d", timestamp) = '20220307'
      AND url LIKE '%https://github.com%'
      AND url NOT LIKE '%github.com/blog/%'
    GROUP BY 1,2,3,4,5,6
    
[2022-06-06 16:59:58,022] {logging_mixin.py:104} WARNING - /home/airflow/.local/lib/python3.6/site-packages/airflow/providers/google/cloud/hooks/bigquery.py:2052 DeprecationWarning: This method is deprecated. Please use `BigQueryHook.insert_job` method.
[2022-06-06 16:59:58,033] {bigquery.py:1510} INFO - Inserting job airflow_1654534798031601_47296cbf7f9df7d8ed633d4f8cc0123a
[2022-06-06 17:00:06,140] {taskinstance.py:1166} INFO - Marking task as SUCCESS. dag_id=gbq_pipeline, task_id=write_truncate_hackernews_agg, execution_date=20220307T100000, start_date=20220606T165957, end_date=20220606T170006
[2022-06-06 17:00:06,164] {taskinstance.py:1220} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-06-06 17:00:06,206] {local_task_job.py:146} INFO - Task exited with return code 0
